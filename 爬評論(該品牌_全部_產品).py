# -*- coding: utf-8 -*-
"""爬評論(該品牌"全部"產品)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Yswxjh9mzZLMWdR4TU4nLoLObRPJ3W8E

# 提取資料

# **輸入品牌名稱找ID，找該品牌"全部"產品的產品名稱/價錢/評論內容/評論評分**
"""

import requests
from bs4 import BeautifulSoup
import re

# 第一段程式碼
url = "https://www.cosme.net.tw/brand-list"
headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}
response = requests.get(url, headers=headers)
response.encoding = 'utf8'

soup = BeautifulSoup(response.text, 'html.parser')

# 讓使用者輸入希望搜索的品牌名稱
search_brand_name = input("請輸入希望搜索的品牌名稱: ")

# 找到 id="brands-list" 中指定品牌名稱的所有 class="uc-brand-list-brand" 元素
brand_elements = soup.select(f'#brands-list .uc-brand-list-brand:contains("{search_brand_name}")')

# 遍歷每個元素
for brand in brand_elements:
    brand_name = brand.text.strip()
    print("品牌:", brand_name)

    # 找到每個 class="uc-brand-list-brand" 元素中的 class="uc-minor-link" 的元素
    minor_link = brand.find(class_="uc-minor-link")

    # 如果找到了 class="uc-minor-link" 元素，提取並列印 href 屬性
    if minor_link:
        href_attribute = minor_link.get('href', 'N/A')

        # 使用正則表達式提取 Minor Link Href 中的品牌 ID
        brand_id_match = re.search(r'/brands/(\d+)', href_attribute)
        if brand_id_match:
            brand_id = brand_id_match.group(1)
            print("Brand ID:", brand_id)

            # 構建評論網址
            review_url = f"https://www.cosme.net.tw/brands/{brand_id}/reviews"
            print("評論網址:", review_url)

            # 第二段程式碼
            # 基本 URL
            base_url_template = f"https://www.cosme.net.tw/brands/{brand_id}/reviews?page="
            headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}

            review_number = 0

            page_number = 1
            base_url = base_url_template

            while True:
                url = f"{base_url}{page_number}"
                response = requests.get(url, headers=headers)
                response.encoding = 'utf8'

                soup = BeautifulSoup(response.text, 'html.parser')

                # 檢查是否有評論
                reviews = soup.find_all(class_="uc-review uc-review-with-product")
                if not reviews:
                    print(f"品牌 {brand_id} 沒有更多評論，停止執行。")
                    break

                all_text=''

                for review in reviews:
                    # 在每個評論中找到class="product-info"元素(每個產品總資訊)
                    product_info = review.find(class_="product-info")

                    # 在class="product-info"中找到class="product-name"元素（產品名稱）
                    product_name = product_info.find(class_="product-name").text.strip() if product_info else "N/A"

                    # 在class="product-info"中找到class="product-info-others"元素（其他信息 容量＆價錢）
                    product_others = product_info.find(class_="product-info-others").text.strip() if product_info else "N/A"

                    # 在評論中找到class="two-line-dot uc-content-link"元素（評論）
                    content_link = review.find(class_="two-line-dot uc-content-link")

                    # 在評論中找到class="review-score"元素（幾顆星）
                    review_score = review.find(class_="review-score")

                    # 提取class="two-line-dot uc-content-link"中的文字（評論）
                    content_text = content_link.text.strip()

                    # 提取class="review-score"中的文字（幾顆星）
                    review_score_text = review_score.text.strip() if review_score else "N/A"

                    #分析或生成文字雲等任務時使用的數據準備步驟
                    all_text += product_name

                    # 打印提取的數據，不包括品牌 ID
                    review_number += 1  # 每迭代一次增加評論編號
                    print(f"編號: {review_number}")
                    print("產品名稱:", product_name)
                    print("其他信息:", product_others)
                    print("評論內容:", content_text)
                    print("評論評分:", review_score_text)
                    print("----")

                # 如果到最後一頁，則結束循環
                if "沒有更多頁面的標誌" in response.text:
                    break

                page_number +=   # 下一頁

    print("----")