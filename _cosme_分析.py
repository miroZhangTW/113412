# -*- coding: utf-8 -*-
"""@cosme 分析.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oGHqS0ECMZBpdth8GckZLVCG9_aoEDY5

# 提取資料

# **輸入品牌名找ID，找該品牌之"特定"產品的產品名稱/價錢/評論內容/評論評分**
"""

import requests
from bs4 import BeautifulSoup
import re

# 第一段程式碼
url = "https://www.cosme.net.tw/brand-list"
headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}
response = requests.get(url, headers=headers)
response.encoding = 'utf8'

soup = BeautifulSoup(response.text, 'html.parser')

# 讓使用者輸入希望搜索的品牌名稱
search_brand_name = input("請輸入希望搜索的品牌名稱: ")

# 找到 id="brands-list" 中指定品牌名稱的所有 class="uc-brand-list-brand" 元素
brand_elements = soup.select(f'#brands-list .uc-brand-list-brand:contains("{search_brand_name}")')

# 遍歷每個元素
for brand in brand_elements:
    brand_name = brand.text.strip()
    print("品牌:", brand_name)

    # 找到每個 class="uc-brand-list-brand" 元素中的 class="uc-minor-link" 的元素
    minor_link = brand.find(class_="uc-minor-link")

    # 如果找到了 class="uc-minor-link" 元素，提取並列印 href 屬性
    if minor_link:
        href_attribute = minor_link.get('href', 'N/A')

        # 使用正則表達式提取 Minor Link Href 中的品牌 ID
        brand_id_match = re.search(r'/brands/(\d+)', href_attribute)
        if brand_id_match:
            brand_id = brand_id_match.group(1)
            print("Brand ID:", brand_id)

            # 構建評論網址
            review_url = f"https://www.cosme.net.tw/brands/{brand_id}/reviews"
            print("評論網址:", review_url)

            # 第二段程式碼
            # 輸入品牌、產品關鍵字
            search_keyword = input("請輸入搜尋產品、品牌: ")

            base_url_template = f"https://www.cosme.net.tw/brands/{brand_id}/reviews?page="
            headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}

            review_number = 0

            page_number = 1
            base_url = base_url_template

            total_score=0
            total_reviews=0

            while True:
                url = f"{base_url}{page_number}"
                response = requests.get(url, headers=headers)
                response.encoding = 'utf8'

                soup = BeautifulSoup(response.text, 'html.parser')

                # 檢查是否有評論
                reviews = soup.find_all(class_="uc-review uc-review-with-product")
                if not reviews:
                    print(f"品牌 {brand_id} 沒有更多評論，停止執行。")
                    break

                all_text=''

                for review in reviews:
                    # 在每個評論中找到class="product-info"元素
                    product_info = review.find(class_="product-info")

                    # 提取class="product-info-name single-dot"中的文字
                    product_name_element = product_info.find(class_="product-info-name single-dot")
                    product_name = product_name_element.text.strip() if product_name_element else "N/A"

                    # 提取class="product-info-others"中的文字
                    product_info_others_element = product_info.find(class_="product-info-others")
                    product_info_others = product_info_others_element.text.strip() if product_info_others_element else "N/A"

                    # 如果產品包含關鍵字，顯示
                    if search_keyword.lower() in product_name.lower():
                        # 在評論中找到class="two-line-dot uc-content-link"元素
                        content_link = review.find(class_="two-line-dot uc-content-link")

                        # 在評論中找到class="review-score"元素
                        review_score = review.find(class_="review-score")

                        # 提取class="two-line-dot uc-content-link"中的文字
                        content_text = content_link.text.strip()

                        # 提取class="review-score"中的文字，如果不是1~7的字串就顯示空格
                        review_score_text = review_score.text.strip() if review_score and review_score.text.strip() in map(str, range(1, 8)) else " "

                        all_text += content_text

                        # 只有在符合條件時才顯示該整筆編號
                        if review_score_text != " ":
                            review_number += 1  # 每迭代一次增加評論
                            total_score += int(review_score_text)
                            total_reviews += 1

                            # 打印提取的數據，不包括品牌 ID
                            print(f"編號: {review_number}")
                            print("產品名稱:", product_name)
                            print("其他信息:", product_info_others)
                            print("評論內容:", content_text)
                            print("評論評分:", review_score_text)
                            print("----")

                # 如果到最后一页，則結束循環
                if "沒有更多頁面的標誌" in response.text:
                    break

                page_number += 1

    print("----")

from google.colab import drive
drive.mount('/content/drive')

import os.path           # 系統功能模組
import numpy           # 分析模組
from collections import Counter # 次數統計模組

from google.colab import files  # colab檔案處理模組
from PIL import Image      # 圖片處理模組
import jieba            # 分詞模組
import matplotlib.pyplot as plt # 視覺化模組
import wordcloud          # 文字雲模組

WORDS_PATH = '/content/drive/My Drive/IPython/dict.txt.big.txt' # 繁體中文詞庫檔名
TC_FONT_PATH = '/content/drive/My Drive/IPython/NotoSansTC-Regular.ttf' # 繁體中文字型檔名
jieba.set_dictionary(WORDS_PATH)

seg_list = jieba.cut(all_text,cut_all=False)

dictionary = Counter(seg_list)

STOP_WORDS = [' ', '，', '（', '）', '...', '。', '「', '」', '[', ']','，',',','…','我','的','為','了','就','是','很']
[dictionary.pop(x, None) for x in STOP_WORDS] # 從字典裡刪除停用詞

average_score = total_score / total_reviews

print("平均評分:",round(average_score,2))
print(dictionary) # 把計算完的每個分詞出現次數顯示出來看看

wc = wordcloud.WordCloud(background_color='white',
                         margin=2, # 文字間距
                         font_path=TC_FONT_PATH, # 設定字體
                         max_words=200, # 取多少文字在裡面
                         width=1280, height=720) # 解析度

wc.generate_from_frequencies(dictionary) # 吃入次數字典資料

wc.to_file('WordCloud.png')

plt.imshow(wc)

"""# **輸入品牌名稱找ID，找該品牌"全部"產品的產品名稱/價錢/評論內容/評論評分**"""

import requests
from bs4 import BeautifulSoup
import re

# 第一段程式碼
url = "https://www.cosme.net.tw/brand-list"
headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}
response = requests.get(url, headers=headers)
response.encoding = 'utf8'

soup = BeautifulSoup(response.text, 'html.parser')

# 讓使用者輸入希望搜索的品牌名稱
search_brand_name = input("請輸入希望搜索的品牌名稱: ")

# 找到 id="brands-list" 中指定品牌名稱的所有 class="uc-brand-list-brand" 元素
brand_elements = soup.select(f'#brands-list .uc-brand-list-brand:contains("{search_brand_name}")')

# 遍歷每個元素
for brand in brand_elements:
    brand_name = brand.text.strip()
    print("品牌:", brand_name)

    # 找到每個 class="uc-brand-list-brand" 元素中的 class="uc-minor-link" 的元素
    minor_link = brand.find(class_="uc-minor-link")

    # 如果找到了 class="uc-minor-link" 元素，提取並列印 href 屬性
    if minor_link:
        href_attribute = minor_link.get('href', 'N/A')

        # 使用正則表達式提取 Minor Link Href 中的品牌 ID
        brand_id_match = re.search(r'/brands/(\d+)', href_attribute)
        if brand_id_match:
            brand_id = brand_id_match.group(1)
            print("Brand ID:", brand_id)

            # 構建評論網址
            review_url = f"https://www.cosme.net.tw/brands/{brand_id}/reviews"
            print("評論網址:", review_url)

            # 第二段程式碼
            # 基本 URL
            base_url_template = f"https://www.cosme.net.tw/brands/{brand_id}/reviews?page="
            headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}

            review_number = 0

            page_number = 1
            base_url = base_url_template

            while True:
                url = f"{base_url}{page_number}"
                response = requests.get(url, headers=headers)
                response.encoding = 'utf8'

                soup = BeautifulSoup(response.text, 'html.parser')

                # 檢查是否有評論
                reviews = soup.find_all(class_="uc-review uc-review-with-product")
                if not reviews:
                    print(f"品牌 {brand_id} 沒有更多評論，停止執行。")
                    break

                all_text=''

                for review in reviews:
                    # 在每個評論中找到class="product-info"元素(每個產品總資訊)
                    product_info = review.find(class_="product-info")

                    # 在class="product-info"中找到class="product-name"元素（產品名稱）
                    product_name = product_info.find(class_="product-name").text.strip() if product_info else "N/A"

                    # 在class="product-info"中找到class="product-info-others"元素（其他信息 容量＆價錢）
                    product_others = product_info.find(class_="product-info-others").text.strip() if product_info else "N/A"

                    # 在評論中找到class="two-line-dot uc-content-link"元素（評論）
                    content_link = review.find(class_="two-line-dot uc-content-link")

                    # 在評論中找到class="review-score"元素（幾顆星）
                    review_score = review.find(class_="review-score")

                    # 提取class="two-line-dot uc-content-link"中的文字（評論）
                    content_text = content_link.text.strip()

                    # 提取class="review-score"中的文字（幾顆星）
                    review_score_text = review_score.text.strip() if review_score else "N/A"

                    #分析或生成文字雲等任務時使用的數據準備步驟
                    all_text += product_name

                    # 打印提取的數據，不包括品牌 ID
                    review_number += 1  # 每迭代一次增加評論編號
                    print(f"編號: {review_number}")
                    print("產品名稱:", product_name)
                    print("其他信息:", product_others)
                    print("評論內容:", content_text)
                    print("評論評分:", review_score_text)
                    print("----")

                # 如果到最後一頁，則結束循環
                if "沒有更多頁面的標誌" in response.text:
                    break

                page_number +=   # 下一頁

    print("----")

import os.path           # 系統功能模組
import numpy           # 分析模組
from collections import Counter # 次數統計模組

from google.colab import files  # colab檔案處理模組
from PIL import Image      # 圖片處理模組
import jieba            # 分詞模組
import matplotlib.pyplot as plt # 視覺化模組
import wordcloud          # 文字雲模組

#這裡設定了分詞所需的中文詞庫檔案路徑和繁體中文字型檔案路徑。
WORDS_PATH = '/content/drive/My Drive/IPython/dict.txt.big.txt' # 繁體中文詞庫檔名
TC_FONT_PATH = '/content/drive/My Drive/IPython/NotoSansTC-Regular.ttf' # 繁體中文字型檔名
jieba.set_dictionary(WORDS_PATH)

seg_list = jieba.cut(all_text,cut_all=False)

#使用 collections.Counter 類別統計每個分詞在文本中出現的次數。
dictionary = Counter(seg_list)

#定義了一個停用詞列表 STOP_WORDS，然後使用列表推導式從字典中刪除這些停用詞。
STOP_WORDS = [' ', '，', '（', '）', '...', '。', '「', '」', '[', ']','，',',','…']
[dictionary.pop(x, None) for x in STOP_WORDS] # 從字典裡刪除停用詞

print(dictionary) # 把計算完的每個分詞出現次數顯示出來看看

wc = wordcloud.WordCloud(background_color='white',
                         margin=2, # 文字間距
                         font_path=TC_FONT_PATH, # 設定字體
                         max_words=20, # 取多少文字在裡面
                         width=1280, height=720) # 解析度

wc.generate_from_frequencies(dictionary) # 吃入次數字典資料

#將生成的文字雲圖片儲存為 'WordCloud.png' 文件。
wc.to_file('WordCloud.png')

plt.imshow(wc)